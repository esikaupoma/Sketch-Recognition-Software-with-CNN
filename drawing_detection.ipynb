{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc26a1c0",
   "metadata": {},
   "source": [
    "## <center>Drawing Detection and Classification<center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb7e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-01-01 04:25:35.116046\n"
     ]
    }
   ],
   "source": [
    "# calculate total execution time\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "print('Start Time: {}'.format(start_time)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2662c",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imutils\n",
    "from imutils.contours import sort_contours\n",
    "from keras.models import load_model\n",
    "# from rembg import remove\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306442a",
   "metadata": {},
   "source": [
    "## Loading the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66ed04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "datadir = 'dataset'\n",
    "for folder in os.listdir(datadir):\n",
    "    print(folder)\n",
    "    path = os.path.join(datadir, folder)\n",
    "    for images in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path, images))\n",
    "        x.append(img)\n",
    "        y.append(folder)\n",
    "        \n",
    "        \n",
    "print(len(x))\n",
    "print(len(y))\n",
    "#print(f'labels : {list(set(y))}')\n",
    "print(f'labels: {sorted(list(set(y)))}')\n",
    "\n",
    "\n",
    "        \n",
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82debb62",
   "metadata": {},
   "source": [
    "## Visualizing Images in the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe230aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10))\n",
    "j = 0\n",
    "for i in list(sorted(list(set(y)))):\n",
    "    idx = y.index(i)\n",
    "    img = x[idx]\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    figure.add_subplot(5, 5, j+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(i)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3711c7",
   "metadata": {},
   "source": [
    "## Data Distribution of the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, count = np.unique(y, return_counts=True)\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "sb.barplot(x=unique, y=count).set_title('Number of Images per Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69dba0",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(x)):\n",
    "    img = x[i]\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    threshold_image = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)[1]\n",
    "    threshold_image = cv2.resize(threshold_image, (32, 32))\n",
    "    X.append(threshold_image)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(y)\n",
    "print(Y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc86fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train))\n",
    "#for i in range((len(X_train))):\n",
    "    #print(X_train)\n",
    "    \n",
    "print(len(X_test))\n",
    "#for i in range(len(X_test)):\n",
    "    #print(X_test)\n",
    "    \n",
    "print(len(Y_train))\n",
    "#for i in range(len(Y_train)):\n",
    "    #print(Y_train)\n",
    "    \n",
    "print(len(Y_test))\n",
    "#for i in range(len(Y_test)):\n",
    "    #print(Y_test)\n",
    "\n",
    "        \n",
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f56eb0",
   "metadata": {},
   "source": [
    "## Data Distribution in Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c64573",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train, count_train = np.unique(Y_train, return_counts=True)\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "sb.barplot(x=unique_train, y=count_train).set_title('Number of Images per category in Train Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827e494",
   "metadata": {},
   "source": [
    "## Data Distribution in Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb21cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_test, count_test = np.unique(Y_test, return_counts=True)\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "sb.barplot(x=unique_test, y=count_test).set_title('Number of Images per category in Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fd8f8",
   "metadata": {},
   "source": [
    "## Defining the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_recognition(input_shape=(32, 32, 1)):\n",
    "    regularizer = l2(0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv1', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act1'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv2', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act2'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv3', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act3'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(120, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
    "    model.add(Dense(84, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
    "    model.add(Dense(6, activation='softmax', kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
    "    \n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85c034-3bc4-48f8-b2fc-7b8ba180db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_recognition(input_shape=(32, 32, 1)):\n",
    "    regularizer = l2(0.01)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv1', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act1'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv2', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act2'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', \n",
    "                     kernel_initializer=glorot_uniform(seed=0), \n",
    "                     name='conv3', activity_regularizer=regularizer))\n",
    "    model.add(Activation(activation='relu', name='act3'))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(120, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
    "    model.add(Dense(84, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
    "    model.add(Dense(6, activation='softmax', kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
    "    \n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24857e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = drawing_recognition(input_shape=(32, 32, 1))\n",
    "model.summary()\n",
    "\n",
    "        \n",
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f82d3",
   "metadata": {},
   "source": [
    "##  Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    dropEvery = 10\n",
    "    factor = 0.5\n",
    "    lr = initial_learning_rate*(factor**np.floor((1 + epoch)/dropEvery))\n",
    "    return float(lr)\n",
    "\n",
    "checkpoint = ModelCheckpoint('drawing_recognition.h5', \n",
    "                             monitor='val_loss', save_best_only=True, \n",
    "                             verbose=1, mode='min')\n",
    "\n",
    "callbacks = [checkpoint, LearningRateScheduler(step_decay)]\n",
    "\n",
    "\n",
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(zoom_range=0.1,\n",
    "                         width_shift_range=0.05,\n",
    "                         height_shift_range=0.05)\n",
    "hist = model.fit(aug.flow(X_train, Y_train, batch_size=128), batch_size=128, epochs=100, validation_data=(X_test, Y_test))\n",
    "\n",
    "        \n",
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25faf6c7",
   "metadata": {},
   "source": [
    "##  Loss and Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10))\n",
    "plt.plot(hist.history['accuracy'], label='Train Set Accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], label='Test Set Accuracy')\n",
    "plt.title('Accuracy Plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "figure2 = plt.figure(figsize=(10, 10))\n",
    "plt.plot(hist.history['loss'], label='Train Set Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Test Set Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5c5f3",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d617326",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(X_test)\n",
    "ypred = np.argmax(ypred, axis=1)\n",
    "Y_test_hat = np.argmax(Y_test, axis=1)\n",
    "\n",
    "matrix = confusion_matrix(Y_test_hat, ypred)\n",
    "df_cm = pd.DataFrame(matrix, index=[0, 1, 2, 3, 4, 5], \n",
    "                     columns=[0, 1, 2, 3, 4, 5])\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "sb.heatmap(df_cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54383f",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test_hat, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b84c78",
   "metadata": {},
   "source": [
    "## Saving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33402448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('drawing_recognition.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2ff7b",
   "metadata": {},
   "source": [
    "## Total Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Time Calculation #################\n",
    "print(\"\\n\\n### Time Update ###\")\n",
    "end_time = datetime.now()\n",
    "print('End Time: {}'.format(end_time))\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d685fd-b57f-41f5-88fa-29eb1d0e4353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
